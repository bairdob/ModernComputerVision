{"cells":[{"cell_type":"markdown","metadata":{"id":"46c16042"},"source":["UAVid dataset: https://uavid.nl/\n","\n","Steps:\n"," - Install Pytorch via Pip/Conda https://pytorch.org/get-started/locally/\n"," - Download dataset via link: https://disk.yandex.ru/d/Mw39uGBey44azw\n"," - Extract dataset zip archive\n"," - Change `DATASET_DIR` accordingly\n"," - Implement `UAVIDDataset`.\n"," - Run the whole notebook to assess SegNet of `UAVIDSemanticSegmentationModel`\n"," - Modify code of `UAVIDSemanticSegmentationModel` to boost semantic segmentation quality quality of test images. You can choose UNet, PSPnet, DeepLab or something else."],"id":"46c16042"},{"cell_type":"code","execution_count":1,"metadata":{"id":"7ed06a52","colab":{"base_uri":"https://localhost:8080/","height":368},"executionInfo":{"status":"error","timestamp":1651005819016,"user_tz":-180,"elapsed":1763,"user":{"displayName":"krumaable DOBLU","userId":"06230307712195389316"}},"outputId":"bd61a2ae-d96c-441b-c64c-968202f31de0"},"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-d9b916ef6bc0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0malbumentations\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mA\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpaddle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpaddle\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpaddle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'paddle'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}],"source":["import os\n","import cv2\n","import numpy as np\n","import ipywidgets\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","import torchvision\n","import torchvision.transforms as transforms\n","\n","from torch.utils.data import Dataset, DataLoader\n","from tqdm import tqdm\n","\n","from typing import Optional\n","\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","import albumentations as A\n"],"id":"7ed06a52"},{"cell_type":"markdown","metadata":{"id":"bb34bc7b"},"source":["# Dataset"],"id":"bb34bc7b"},{"cell_type":"code","execution_count":null,"metadata":{"id":"2d5d67a8","executionInfo":{"status":"aborted","timestamp":1651005819003,"user_tz":-180,"elapsed":21,"user":{"displayName":"krumaable DOBLU","userId":"06230307712195389316"}}},"outputs":[],"source":["class UAVIDDataset(Dataset):\n","    def __init__(self, dataset_dir: str, image_height: int, image_width: int, train: bool = False):\n","        super(UAVIDDataset, self).__init__()\n","        self.dataset_dir = dataset_dir\n","        self.image_height = image_height\n","        self.image_width = image_width\n","        self.train = train\n","        \n","        dir_suffix = 'train/seq1' if self.train else 'val/seq16'\n","        \n","        self.image_dir = f'{self.dataset_dir}/uavid_{dir_suffix}/Images/'\n","        self.label_path = f'{self.dataset_dir}/uavid_{dir_suffix}/Labels/'\n","\n","        self.index = list(sorted(os.listdir(self.image_dir)))\n","        \n","        # color table.\n","        self.clr_tab = self.createColorTable()\n","\n","        # id table.\n","        id_tab = {}\n","        for k, v in self.clr_tab.items():\n","            id_tab[k] = self.clr2id(v)\n","        self.id_tab = id_tab        \n","        \n","        self.transform = transforms.Compose(\n","            [ \n","                transforms.ToTensor(),\n","                transforms.Normalize(IMAGE_MEAN, IMAGE_STD),\n","                transforms.GaussianBlur(kernel_size=(5, 9), sigma=(0.1, 2))\n","             \n","                # transforms.ColorJitter(brightness=0.2, contrast=0.1, saturation=0.2, hue=0.2),\n","                # transforms.RandomHorizontalFlip(),\n","            ]\n","        )\n","\n","        \n","    def __getitem__(self, index):\n","        image = self.get_np_image(index)\n","        image = np.array(image / 255, dtype=np.float32)\n","        image = self.transform(image)\n","        \n","        label = self.get_np_label(index)\n","        label = self.label_transform(label).astype(np.compat.long)\n","        label = torch.from_numpy(label)\n","        \n","        return image, label\n","        \n","    def get_np_image(self, index): #+\n","        image = cv2.imread(f'{self.image_dir}/{self.index[index]}')\n","        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","        image = cv2.resize(image, (self.image_width, self.image_height), interpolation=cv2.INTER_CUBIC)\n","        return image\n","    \n","    def get_np_label(self, index): #+\n","        image = cv2.imread(f'{self.label_path}/{self.index[index]}')\n","        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","        image = cv2.resize(image, (self.image_width, self.image_height), interpolation=cv2.INTER_CUBIC)\n","        \n","        return image\n","    \n","    def __len__(self):\n","        return len(self.index)\n","    \n","    def createColorTable(self):\n","        clr_tab = {}\n","        clr_tab['Clutter'] = [0, 0, 0]\n","        clr_tab['Building'] = [128, 0, 0]\n","        clr_tab['Road'] = [128, 64, 128]\n","        clr_tab['Static_Car'] = [192, 0, 192]\n","        clr_tab['Tree'] = [0, 128, 0]\n","        clr_tab['Vegetation'] = [128, 128, 0]\n","        clr_tab['Human'] = [64, 64, 0]\n","        clr_tab['Moving_Car'] = [64, 0, 128]\n","        \n","        return clr_tab\n","\n","    def colorTable(self):\n","        return self.clr_tab\n","\n","    def clr2id(self, clr):\n","        return clr[0]+clr[1]*255+clr[2]*255*255\n","    \n","    #transform to uint8 integer label\n","    def label_transform(self,label, dtype=np.int32):\n","        height,width = label.shape[:2]\n","        # default value is index of clutter.\n","        newLabel = np.zeros((height, width), dtype=dtype)\n","        id_label = label.astype(np.int64)\n","        id_label = id_label[:,:,0]+id_label[:,:,1]*255+id_label[:,:,2]*255*255\n","        for tid,key in enumerate(self.clr_tab.keys()):\n","            val = self.id_tab[key]\n","            mask = (id_label == val)\n","            newLabel[mask] = tid\n","            \n","        return newLabel\n","\n","    #transform back to 3 channels uint8 label\n","    def inverse_transform(self, label):\n","        label_img = np.zeros(shape=(label.shape[0], label.shape[1],3),dtype=np.uint8)\n","        values = list(self.clr_tab.values())\n","        for tid,val in enumerate(values):\n","            mask = (label==tid)\n","            label_img[mask] = val\n","            \n","        return label_img\n","\n","def create_dataloader(dataset: Dataset, batch_size: int, num_workers: int, train: bool = False):\n","    return DataLoader(\n","        dataset=dataset, batch_size=batch_size, \n","        shuffle=train, num_workers=num_workers,\n","        pin_memory=True, drop_last=False)"],"id":"2d5d67a8"},{"cell_type":"markdown","metadata":{"id":"8347381b"},"source":["# Metric"],"id":"8347381b"},{"cell_type":"code","execution_count":null,"metadata":{"id":"9f523cfb","executionInfo":{"status":"aborted","timestamp":1651005819004,"user_tz":-180,"elapsed":21,"user":{"displayName":"krumaable DOBLU","userId":"06230307712195389316"}}},"outputs":[],"source":["class IOU(nn.Module):\n","    def __init__(self, eps=1.0, activation=None):\n","        super().__init__()\n","        self.eps = eps\n","        if activation is None:\n","            self.activation = torch.sigmoid\n","        else:\n","            self.activation = activation\n","\n","    def forward(self, y_pr, y_gt):\n","        if self.activation is not None:\n","            y_pr = self.activation(y_pr)\n","        y_pr = y_pr > 0.5\n","        y_gt = gt_to_stacked(y_pr, y_gt)\n","        return get_iou(y_pr, y_gt, eps=self.eps)\n","\n","    \n","def gt_to_stacked(pred, gt):\n","    stacked = torch.zeros_like(pred)\n","    for i in range(pred.shape[1]):\n","        stacked[:, i, ...] = gt == i\n","    return stacked\n","    \n","    \n","def get_iou(pr, gt, eps=1e-6):    \n","    ious = list()\n","    \n","    for i in range(pr.shape[1]):\n","        gt_i = gt[:, i, ...]\n","        pr_i = pr[:, i, ...]\n","        intersection = torch.sum(gt_i * pr_i)\n","        union = torch.sum(gt_i) + torch.sum(pr_i) - intersection + eps\n","        iou_i = (intersection + eps) / union\n","        ious.append(iou_i)\n","    \n","    return sum(ious) / len(ious)"],"id":"9f523cfb"},{"cell_type":"markdown","metadata":{"id":"w0Fy1khy7xQ0"},"source":["# Loss function"],"id":"w0Fy1khy7xQ0"},{"cell_type":"code","execution_count":null,"metadata":{"id":"cYKv88PC7uY3","executionInfo":{"status":"aborted","timestamp":1651005819005,"user_tz":-180,"elapsed":22,"user":{"displayName":"krumaable DOBLU","userId":"06230307712195389316"}}},"outputs":[],"source":["class FocalLoss(nn.Module):\n","    '''\n","    Multi-class Focal loss implementation\n","    '''\n","    def __init__(self, gamma=2, weight=None):\n","        super(FocalLoss, self).__init__()\n","        self.gamma = gamma\n","        self.weight = weight\n","\n","    def forward(self, input, target):\n","        \"\"\"\n","        input: [N, C]\n","        target: [N, ]\n","        \"\"\"\n","        logpt = F.log_softmax(input, dim=1)\n","        pt = torch.exp(logpt)\n","        logpt = (1-pt)**self.gamma * logpt\n","        loss = F.nll_loss(logpt, target, self.weight)\n","        return loss\n","\n","\n","class DiceLoss(nn.Layer):\n","    \"\"\"\n","    The implements of the dice loss.\n","    Args:\n","        weight (list[float], optional): The weight for each class. Default: None.\n","        ignore_index (int64): ignore_index (int64, optional): Specifies a target value that\n","            is ignored and does not contribute to the input gradient. Default ``255``.\n","        smooth (float32): Laplace smoothing to smooth dice loss and accelerate convergence.\n","            Default: 1.0\n","    \"\"\"\n","\n","    def __init__(self, weight=None, ignore_index=255, smooth=1.0):\n","        super().__init__()\n","        self.weight = weight\n","        self.ignore_index = ignore_index\n","        self.smooth = smooth\n","        self.eps = 1e-8\n","\n","    def forward(self, logits, labels):\n","        num_class = logits.shape[1]\n","        if self.weight is not None:\n","            assert num_class == len(self.weight), \\\n","                \"The lenght of weight should be euqal to the num class\"\n","\n","        logits = F.softmax(logits, axis=1)\n","        labels_one_hot = F.one_hot(labels, num_class)\n","        labels_one_hot = paddle.transpose(labels_one_hot, [0, 3, 1, 2])\n","\n","        mask = labels != self.ignore_index\n","        mask = paddle.cast(paddle.unsqueeze(mask, 1), 'float32')\n","\n","        dice_loss = 0.0\n","        for i in range(num_class):\n","            dice_loss_i = dice_loss_helper(logits[:, i], labels_one_hot[:, i],\n","                                           mask, self.smooth, self.eps)\n","            if self.weight is not None:\n","                dice_loss_i *= self.weight[i]\n","            dice_loss += dice_loss_i\n","        dice_loss = dice_loss / num_class\n","\n","        return dice_loss\n","\n","\n","def dice_loss_helper(logit, label, mask, smooth, eps):\n","    assert logit.shape == label.shape, \\\n","        \"The shape of logit and label should be the same\"\n","    logit = paddle.reshape(logit, [0, -1])\n","    label = paddle.reshape(label, [0, -1])\n","    mask = paddle.reshape(mask, [0, -1])\n","    logit *= mask\n","    label *= mask\n","    intersection = paddle.sum(logit * label, axis=1)\n","    cardinality = paddle.sum(logit + label, axis=1)\n","    dice_loss = 1 - (2 * intersection + smooth) / (cardinality + smooth + eps)\n","    dice_loss = dice_loss.mean()\n","    return dice_loss"],"id":"cYKv88PC7uY3"},{"cell_type":"markdown","metadata":{"id":"3a35f606"},"source":["# Loss"],"id":"3a35f606"},{"cell_type":"code","execution_count":null,"metadata":{"id":"9c1b0dc3","executionInfo":{"status":"aborted","timestamp":1651005819005,"user_tz":-180,"elapsed":21,"user":{"displayName":"krumaable DOBLU","userId":"06230307712195389316"}}},"outputs":[],"source":["# class Loss(nn.Module):\n","#     def __init__(self):\n","#         super().__init__()\n","#         # self.criterion = FocalLoss()\n","#         self.criterion = nn.CrossEntropyLoss()\n","\n","#     def forward(self, outputs, labels):\n","#         return self.criterion(outputs, labels)"],"id":"9c1b0dc3"},{"cell_type":"markdown","metadata":{"id":"4acb6822"},"source":["# Utils"],"id":"4acb6822"},{"cell_type":"code","execution_count":null,"metadata":{"id":"fae14f0b","executionInfo":{"status":"aborted","timestamp":1651005819006,"user_tz":-180,"elapsed":22,"user":{"displayName":"krumaable DOBLU","userId":"06230307712195389316"}}},"outputs":[],"source":["def evaluate(model: nn.Module, dataloader: DataLoader, train: bool = False):\n","    model.eval()\n","    \n","    iou_list = list()\n","    iou_metric = IOU()\n","    \n","    with torch.no_grad():\n","        for data in dataloader:\n","            inputs, labels = data\n","            inputs = inputs.to(device)\n","            labels = labels.to(device)\n","            outputs = model(inputs)\n","            current_iou = iou_metric(outputs, labels).item()\n","            iou_list.append(current_iou)\n","\n","    images = len(dataloader) * dataloader.batch_size\n","    prefix = \"train\" if train else \"test\"\n","    print(f'mIOU of the network on the {images} {prefix} images: {(sum(iou_list) / len(iou_list)):.3f} %')\n","    \n","\n","def plot(imgs, with_orig=True, row_title=None, **imshow_kwargs):\n","    if not isinstance(imgs[0], list):\n","        # Make a 2d grid even if there's just 1 row\n","        imgs = [imgs]\n","\n","    num_rows = len(imgs)\n","    num_cols = len(imgs[0])\n","    fig, axs = plt.subplots(\n","        nrows=num_rows, ncols=num_cols, squeeze=False, figsize=(num_rows * 16, num_cols * 16))\n","\n","    for row_idx, row in enumerate(imgs):\n","        for col_idx, img in enumerate(row):\n","            ax = axs[row_idx, col_idx]\n","            ax.imshow(np.asarray(img), **imshow_kwargs)\n","            ax.set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n","\n","    if row_title is not None:\n","        for row_idx in range(num_rows):\n","            axs[row_idx, 0].set(ylabel=row_title[row_idx])\n","\n","    plt.tight_layout()"],"id":"fae14f0b"},{"cell_type":"markdown","metadata":{"id":"ae106917"},"source":["# Model Segnet"],"id":"ae106917"},{"cell_type":"code","execution_count":null,"metadata":{"id":"0999b7b8","executionInfo":{"status":"aborted","timestamp":1651005819007,"user_tz":-180,"elapsed":22,"user":{"displayName":"krumaable DOBLU","userId":"06230307712195389316"}}},"outputs":[],"source":["class Conv2DBatchNormRelu(nn.Module):\n","    def __init__(\n","        self,\n","        in_channels,\n","        n_filters,\n","        k_size,\n","        stride,\n","        padding,\n","        bias=True,\n","        dilation=1,\n","        is_batchnorm=True,\n","    ):\n","        super(Conv2DBatchNormRelu, self).__init__()\n","\n","        conv_mod = nn.Conv2d(\n","            int(in_channels),\n","            int(n_filters),\n","            kernel_size=k_size,\n","            padding=padding,\n","            stride=stride,\n","            bias=bias,\n","            dilation=(dilation, dilation)\n","        )\n","\n","        if is_batchnorm:\n","            self.cbr_unit = nn.Sequential(\n","                conv_mod, nn.BatchNorm2d(int(n_filters)), nn.ReLU(inplace=True)\n","            )\n","        else:\n","            self.cbr_unit = nn.Sequential(conv_mod, nn.ReLU(inplace=True))\n","\n","    def forward(self, inputs):\n","        outputs = self.cbr_unit(inputs)\n","        return outputs\n","\n","\n","class SegNetDown2(nn.Module):\n","    def __init__(self, in_size, out_size):\n","        super(SegNetDown2, self).__init__()\n","        self.conv1 = Conv2DBatchNormRelu(in_size, out_size, 3, 1, 1)\n","        self.conv2 = Conv2DBatchNormRelu(out_size, out_size, 3, 1, 1)\n","        self.maxpool_with_argmax = nn.MaxPool2d(2, 2, return_indices=True)\n","\n","    def forward(self, inputs):\n","        outputs = self.conv1(inputs)\n","        outputs = self.conv2(outputs)\n","        unpooled_shape = outputs.size()\n","        outputs, indices = self.maxpool_with_argmax(outputs)\n","        return outputs, indices, unpooled_shape\n","\n","\n","class SegNetUp2(nn.Module):\n","    def __init__(self, in_size, out_size):\n","        super(SegNetUp2, self).__init__()\n","        self.unpool = nn.MaxUnpool2d(2, 2)\n","        self.conv1 = Conv2DBatchNormRelu(in_size, in_size, 3, 1, 1)\n","        self.conv2 = Conv2DBatchNormRelu(in_size, out_size, 3, 1, 1)\n","\n","    def forward(self, inputs, indices, output_shape):\n","        outputs = self.unpool(input=inputs, indices=indices, output_size=output_shape)\n","        outputs = self.conv1(outputs)\n","        outputs = self.conv2(outputs)\n","        return outputs\n","\n","\n","class SegNet(nn.Module):\n","    def __init__(self, in_channels=3, num_classes=1, is_unpooling=True):\n","        super(SegNet, self).__init__()\n","        self.in_channels = in_channels\n","        self.is_unpooling = is_unpooling\n","\n","        self.down1 = SegNetDown2(self.in_channels, 128)\n","        self.down2 = SegNetDown2(128, 256)\n","\n","        self.up2 = SegNetUp2(256, 128)\n","        self.up1 = SegNetUp2(128, 64)\n","\n","        self.classification = nn.Conv2d(64, num_classes, kernel_size=(3, 3), padding=1)\n","\n","    def forward(self, inputs):\n","        down1, indices_1, unpool_shape1 = self.down1(inputs)\n","        down2, indices_2, unpool_shape2 = self.down2(down1)\n","        up2 = self.up2(down2, indices_2, unpool_shape2)\n","        up1 = self.up1(up2, indices_1, unpool_shape1)\n","        semantic = self.classification(up1)\n","        return semantic\n","    \n","    \n","class UAVIDSemanticSegmentationModel(nn.Module):\n","    def __init__(self, num_classes: int):\n","        super(UAVIDSemanticSegmentationModel, self).__init__()\n","        self.model = SegNet(num_classes=num_classes)\n","\n","    def forward(self, x):\n","        y = self.model(x)\n","        return y"],"id":"0999b7b8"},{"cell_type":"markdown","metadata":{"id":"X-GfFPaFpQZ2"},"source":["# Model Unet"],"id":"X-GfFPaFpQZ2"},{"cell_type":"code","execution_count":null,"metadata":{"id":"shyLTxUgpZfW","executionInfo":{"status":"aborted","timestamp":1651005819008,"user_tz":-180,"elapsed":23,"user":{"displayName":"krumaable DOBLU","userId":"06230307712195389316"}}},"outputs":[],"source":["def convrelu(in_channels, out_channels, kernel, padding):\n","  return nn.Sequential(\n","    nn.Conv2d(in_channels, out_channels, kernel, padding=padding),\n","    nn.ReLU(inplace=True),\n","  )\n","\n","\n","class ResNetUNet(nn.Module):\n","  def __init__(self, n_class):\n","    super().__init__()\n","\n","    self.base_model = torchvision.models.resnet18(pretrained=True)\n","    self.base_layers = list(self.base_model.children())\n","\n","    self.layer0 = nn.Sequential(*self.base_layers[:3]) # size=(N, 64, x.H/2, x.W/2)\n","    self.layer0_1x1 = convrelu(64, 64, 1, 0)\n","    self.layer1 = nn.Sequential(*self.base_layers[3:5]) # size=(N, 64, x.H/4, x.W/4)\n","    self.layer1_1x1 = convrelu(64, 64, 1, 0)\n","    self.layer2 = self.base_layers[5]  # size=(N, 128, x.H/8, x.W/8)\n","    self.layer2_1x1 = convrelu(128, 128, 1, 0)\n","    self.layer3 = self.base_layers[6]  # size=(N, 256, x.H/16, x.W/16)\n","    self.layer3_1x1 = convrelu(256, 256, 1, 0)\n","    self.layer4 = self.base_layers[7]  # size=(N, 512, x.H/32, x.W/32)\n","    self.layer4_1x1 = convrelu(512, 512, 1, 0)\n","\n","    self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n","\n","    self.conv_up3 = convrelu(256 + 512, 512, 3, 1)\n","    self.conv_up2 = convrelu(128 + 512, 256, 3, 1)\n","    self.conv_up1 = convrelu(64 + 256, 256, 3, 1)\n","    self.conv_up0 = convrelu(64 + 256, 128, 3, 1)\n","\n","    self.conv_original_size0 = convrelu(3, 64, 3, 1)\n","    self.conv_original_size1 = convrelu(64, 64, 3, 1)\n","    self.conv_original_size2 = convrelu(64 + 128, 64, 3, 1)\n","\n","    self.conv_last = nn.Conv2d(64, n_class, 1)\n","\n","  def forward(self, input):\n","    x_original = self.conv_original_size0(input)\n","    x_original = self.conv_original_size1(x_original)\n","\n","    layer0 = self.layer0(input)\n","    layer1 = self.layer1(layer0)\n","    layer2 = self.layer2(layer1)\n","    layer3 = self.layer3(layer2)\n","    layer4 = self.layer4(layer3)\n","\n","    layer4 = self.layer4_1x1(layer4)\n","    x = self.upsample(layer4)\n","    layer3 = self.layer3_1x1(layer3)\n","    x = torch.cat([x, layer3], dim=1)\n","    x = self.conv_up3(x)\n","\n","    x = self.upsample(x)\n","    layer2 = self.layer2_1x1(layer2)\n","    x = torch.cat([x, layer2], dim=1)\n","    x = self.conv_up2(x)\n","\n","    x = self.upsample(x)\n","    layer1 = self.layer1_1x1(layer1)\n","    x = torch.cat([x, layer1], dim=1)\n","    x = self.conv_up1(x)\n","\n","    x = self.upsample(x)\n","    layer0 = self.layer0_1x1(layer0)\n","    x = torch.cat([x, layer0], dim=1)\n","    x = self.conv_up0(x)\n","\n","    x = self.upsample(x)\n","    x = torch.cat([x, x_original], dim=1)\n","    x = self.conv_original_size2(x)\n","\n","    out = self.conv_last(x)\n","\n","    return out"],"id":"shyLTxUgpZfW"},{"cell_type":"markdown","source":["# ResNet18"],"metadata":{"id":"L2ect7u2hFBz"},"id":"L2ect7u2hFBz"},{"cell_type":"code","source":["class DilatedCNN(nn.Module):\n","  def __init__(self):\n","    super(DilatedCNN,self).__init__()\n","    self.convlayers = nn.Sequential(\n","      nn.Conv2d(in_channels = 3, out_channels = 6, kernel_size = 9, stride = 1, padding = 0, dilation=2),\n","      nn.ReLU(),\n","      nn.Conv2d(in_channels=6, out_channels=16, kernel_size = 3, stride = 1, padding= 0, dilation = 2),\n","      nn.ReLU(),\n","    )\n","    self.fclayers = nn.Sequential(\n","      nn.Linear(2304,120),\n","      nn.ReLU(),\n","      nn.Linear(120,84),\n","      nn.ReLU(),\n","      nn.Linear(84,8)\n","    )\n","  def forward(self,x):\n","    x = self.convlayers(x)\n","    x = x.view(-1,2304)\n","    x = self.fclayers(x)\n","    return x"],"metadata":{"id":"smr__TZwaosR","executionInfo":{"status":"aborted","timestamp":1651005819008,"user_tz":-180,"elapsed":22,"user":{"displayName":"krumaable DOBLU","userId":"06230307712195389316"}}},"id":"smr__TZwaosR","execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"61873745"},"source":["# Parameters"],"id":"61873745"},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":23,"status":"aborted","timestamp":1651005819009,"user":{"displayName":"krumaable DOBLU","userId":"06230307712195389316"},"user_tz":-180},"id":"UM3POTzd27j6"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"id":"UM3POTzd27j6"},{"cell_type":"code","execution_count":null,"metadata":{"id":"0b7a3742","executionInfo":{"status":"aborted","timestamp":1651005819009,"user_tz":-180,"elapsed":23,"user":{"displayName":"krumaable DOBLU","userId":"06230307712195389316"}}},"outputs":[],"source":["DATASET_DIR = '/content/drive/MyDrive/Colab Notebooks/uavid'\n","\n","NUM_CLASSES = 8\n","\n","IMAGE_HEIGHT = 256\n","IMAGE_WIDTH = 256\n","\n","IMAGE_MEAN = [0.485, 0.456, 0.406]\n","IMAGE_STD = [0.229, 0.224, 0.225]\n","\n","BATCH_SIZE = 8\n","NUM_WORKERS = 2\n","EPOCHS = 8\n","\n","CHECKPOINT_PATH = f'./uavid_semantic_segmentation_model_{IMAGE_HEIGHT}_{IMAGE_WIDTH}.pth'"],"id":"0b7a3742"},{"cell_type":"markdown","metadata":{"id":"8085a5bb"},"source":["# Datasets"],"id":"8085a5bb"},{"cell_type":"code","execution_count":null,"metadata":{"id":"bf8c2dea","executionInfo":{"status":"aborted","timestamp":1651005819009,"user_tz":-180,"elapsed":22,"user":{"displayName":"krumaable DOBLU","userId":"06230307712195389316"}}},"outputs":[],"source":["train_dataset = UAVIDDataset(\n","    dataset_dir=DATASET_DIR, image_height=IMAGE_HEIGHT, image_width=IMAGE_WIDTH, train=True)\n","\n","val_dataset = UAVIDDataset(\n","    dataset_dir=DATASET_DIR, image_height=IMAGE_HEIGHT, image_width=IMAGE_WIDTH)\n","\n","train_dataloader = create_dataloader(\n","    train_dataset, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, train=True)\n","\n","val_dataloader = create_dataloader(\n","    val_dataset, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS)"],"id":"bf8c2dea"},{"cell_type":"markdown","metadata":{"id":"fcc7cf22"},"source":["# Data examples"],"id":"fcc7cf22"},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":23,"status":"aborted","timestamp":1651005819010,"user":{"displayName":"krumaable DOBLU","userId":"06230307712195389316"},"user_tz":-180},"id":"6d6f2d66"},"outputs":[],"source":["indices = [0, 100, 200]\n","plot([train_dataset.get_np_image(index) for index in indices]);"],"id":"6d6f2d66"},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":23,"status":"aborted","timestamp":1651005819010,"user":{"displayName":"krumaable DOBLU","userId":"06230307712195389316"},"user_tz":-180},"id":"b68455be"},"outputs":[],"source":["indices = [0, 100, 200]\n","plot([train_dataset.get_np_label(index) for index in indices]);"],"id":"b68455be"},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":24,"status":"aborted","timestamp":1651005819011,"user":{"displayName":"krumaable DOBLU","userId":"06230307712195389316"},"user_tz":-180},"id":"5970c343"},"outputs":[],"source":["indices = [0, 100, 200]\n","plot([train_dataset[index][1].squeeze(0).numpy() for index in indices]);"],"id":"5970c343"},{"cell_type":"code","execution_count":null,"metadata":{"id":"3db1c200","executionInfo":{"status":"aborted","timestamp":1651005819011,"user_tz":-180,"elapsed":24,"user":{"displayName":"krumaable DOBLU","userId":"06230307712195389316"}}},"outputs":[],"source":["images, _ = next(iter(val_dataloader))\n","plt.figure(figsize=(16, 8))\n","plt.imshow(torchvision.utils.make_grid(images).permute(1, 2, 0));"],"id":"3db1c200"},{"cell_type":"code","execution_count":null,"metadata":{"id":"2eeef521","executionInfo":{"status":"aborted","timestamp":1651005819012,"user_tz":-180,"elapsed":24,"user":{"displayName":"krumaable DOBLU","userId":"06230307712195389316"}}},"outputs":[],"source":["device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","\n","# model = UAVIDSemanticSegmentationModel(num_classes=NUM_CLASSES).to(device)\n","# model = DilatedCNN().to(device)\n","model = ResNetUNet(NUM_CLASSES).to(device)\n","\n","# criterion = nn.CrossEntropyLoss()\n","# criterion = FocalLoss()\n","criterion = DiceLoss()\n","\n","# optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n","optimizer = optim.Adam(model.parameters(), lr=0.001)"],"id":"2eeef521"},{"cell_type":"markdown","metadata":{"id":"1aad5a85"},"source":["# Training"],"id":"1aad5a85"},{"cell_type":"code","execution_count":null,"metadata":{"id":"374df611","executionInfo":{"status":"aborted","timestamp":1651005819012,"user_tz":-180,"elapsed":24,"user":{"displayName":"krumaable DOBLU","userId":"06230307712195389316"}}},"outputs":[],"source":["model.train()\n","\n","for epoch in range(EPOCHS):\n","    running_loss = list()\n","\n","    for i, data in tqdm(enumerate(train_dataloader), total=len(train_dataloader)):\n","        inputs, labels = data\n","        inputs = inputs.to(device)\n","        labels = labels.to(device)\n","        optimizer.zero_grad()\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","        running_loss.append(loss.item())\n","    \n","    print(f'epoch: {epoch:2d}, iteration: {i + 1:4d}, loss: {sum(running_loss) / len(running_loss):.4f}')\n","            \n","model.eval();"],"id":"374df611"},{"cell_type":"markdown","metadata":{"id":"c4f4bbb7"},"source":["# Saving model"],"id":"c4f4bbb7"},{"cell_type":"code","execution_count":null,"metadata":{"id":"4f2b08e1","executionInfo":{"status":"aborted","timestamp":1651005819013,"user_tz":-180,"elapsed":24,"user":{"displayName":"krumaable DOBLU","userId":"06230307712195389316"}}},"outputs":[],"source":["torch.save(model.state_dict(), CHECKPOINT_PATH)"],"id":"4f2b08e1"},{"cell_type":"markdown","metadata":{"id":"87611dd9"},"source":["# Loading model"],"id":"87611dd9"},{"cell_type":"code","execution_count":null,"metadata":{"id":"e2fecac0","executionInfo":{"status":"aborted","timestamp":1651005819013,"user_tz":-180,"elapsed":24,"user":{"displayName":"krumaable DOBLU","userId":"06230307712195389316"}}},"outputs":[],"source":["model.load_state_dict(torch.load(CHECKPOINT_PATH))\n","model.eval();"],"id":"e2fecac0"},{"cell_type":"markdown","metadata":{"id":"3cdc413a"},"source":["# Evaluation"],"id":"3cdc413a"},{"cell_type":"code","execution_count":null,"metadata":{"id":"ba5e8542","executionInfo":{"status":"aborted","timestamp":1651005819014,"user_tz":-180,"elapsed":24,"user":{"displayName":"krumaable DOBLU","userId":"06230307712195389316"}}},"outputs":[],"source":["evaluate(model, train_dataloader, train=True)"],"id":"ba5e8542"},{"cell_type":"code","execution_count":null,"metadata":{"id":"c42f254c","executionInfo":{"status":"aborted","timestamp":1651005819014,"user_tz":-180,"elapsed":24,"user":{"displayName":"krumaable DOBLU","userId":"06230307712195389316"}}},"outputs":[],"source":["evaluate(model, val_dataloader, train=False)"],"id":"c42f254c"},{"cell_type":"markdown","metadata":{"id":"db221e7f"},"source":["# Visualization"],"id":"db221e7f"},{"cell_type":"code","execution_count":null,"metadata":{"id":"5368556e","executionInfo":{"status":"aborted","timestamp":1651005819014,"user_tz":-180,"elapsed":23,"user":{"displayName":"krumaable DOBLU","userId":"06230307712195389316"}}},"outputs":[],"source":["def plot_model_preds(index):\n","    color_transformer = UAVIDDataset(dataset_dir=DATASET_DIR, image_height=IMAGE_HEIGHT, image_width=IMAGE_WIDTH)\n","\n","    with torch.no_grad():\n","        image, label = val_dataset[index]\n","        image = image.to(device)\n","        label = label.to(device)\n","        outputs = model(image.unsqueeze(0))\n","        _, outputs = torch.max(outputs, 1)\n","        outputs = outputs.squeeze(0).cpu().numpy()\n","        outputs_colored = color_transformer.inverse_transform(outputs)\n","        image = image.cpu().numpy()\n","        label = label.cpu().numpy()\n","        label_colored = color_transformer.inverse_transform(label)\n","\n","    plot([val_dataset.get_np_image(index), outputs_colored, label_colored]);"],"id":"5368556e"},{"cell_type":"code","execution_count":null,"metadata":{"id":"6275feb9","executionInfo":{"status":"aborted","timestamp":1651005819015,"user_tz":-180,"elapsed":24,"user":{"displayName":"krumaable DOBLU","userId":"06230307712195389316"}}},"outputs":[],"source":["ipywidgets.interact(\n","    plot_model_preds,    \n","    index=ipywidgets.IntText(min=0, max=len(val_dataset), step=1, value=0));"],"id":"6275feb9"},{"cell_type":"markdown","metadata":{"id":"6941b80d"},"source":["# What's next?\n","\n","In order to boost segmentation accuracy you can:\n"," - Use State-Of-The-Art model architecture\n"," - Change Loss function\n"," - Play with learning_rate of optimizer\n"," - Increase image resolution\n"," - Add image augmenations"],"id":"6941b80d"},{"cell_type":"code","execution_count":null,"metadata":{"id":"pVKmeV1_ufI2","executionInfo":{"status":"aborted","timestamp":1651005819015,"user_tz":-180,"elapsed":23,"user":{"displayName":"krumaable DOBLU","userId":"06230307712195389316"}}},"outputs":[],"source":["print (model.__class__.__name__)\n","print (criterion.__class__.__name__)\n","print (optimizer.__class__.__name__)"],"id":"pVKmeV1_ufI2"},{"cell_type":"markdown","metadata":{"id":"RsV0qiD91Kcp"},"source":["base: image size 256x256 | 8 epoch | \n","\n","| Model | Loss  | Optimizer | train | test | additional | conclusion |\n","| :-----: | :-: | :-: | :-: | :-: | :-: | :-: |\n","| Segnet | CrossEntropyLoss | SGD | 0.182 | 0.177 | - | \n","| Segnet | Focal | SGD | 0.183 | 0.175 | - | \n","| Segnet | Focal | Adam | 0.235 | 0.219 | - | \n","| Segnet | CrossEntropyLoss | Adam | 0.261 (0.283) | 0.251 (0.267)| - | Adam > SGD|\n","| Unet | CrossEntropyLoss | Adam | 0.173 | 0.164 | - | \n","| Unet | Focal | Adam | 0.233 (0.199) | 0.216 (0.188) | - | focal loss for Unet\n","| Unet | Focal | Adam | 0.162 | 0.172 | aug |\n","| Unet | Focal | Adam | 0.216 | 0.201 | 512 image size | increase image size not giving better results\n","| Unet | Focal | Adam | 0.21 | 0. | 512 image size + 20 epoch |\n","| Unet | Focal | Adam | 0.17 | 0.167 | 256 image size + 16 epoch |\n","| Unet | Focal | Adam | 0.17 | 0.162 | 256 image size + 20 epoch + lr=0.0001|"],"id":"RsV0qiD91Kcp"},{"cell_type":"code","execution_count":null,"metadata":{"id":"e_eJegJuW6a4","executionInfo":{"status":"aborted","timestamp":1651005819015,"user_tz":-180,"elapsed":23,"user":{"displayName":"krumaable DOBLU","userId":"06230307712195389316"}}},"outputs":[],"source":[""],"id":"e_eJegJuW6a4"}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":["8347381b","3a35f606","4acb6822","ae106917","X-GfFPaFpQZ2"],"name":"uavid_semantic_segmentation_notebook.ipynb","provenance":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.10"}},"nbformat":4,"nbformat_minor":5}